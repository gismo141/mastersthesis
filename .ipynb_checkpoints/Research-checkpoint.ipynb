{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed hierarchymagic.py. To use it, type:\n",
      "  %load_ext hierarchymagic\n",
      "Installed asymptote.py. To use it, type:\n",
      "  %load_ext asymptote\n"
     ]
    }
   ],
   "source": [
    "%install_ext https://raw.github.com/tkf/ipython-hierarchymagic/master/hierarchymagic.py\n",
    "%install_ext https://raw.github.com/jrjohansson/ipython-asymptote/master/asymptote.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hierarchymagic extension is already loaded. To reload it, use:\n",
      "  %reload_ext hierarchymagic\n",
      "The asymptote extension is already loaded. To reload it, use:\n",
      "  %reload_ext asymptote\n"
     ]
    }
   ],
   "source": [
    "%load_ext hierarchymagic\n",
    "%load_ext asymptote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einleitung\n",
    "\n",
    "In den letzten Jahren hat das allgemeine Interesse am Autonomen Fahren stark zugenommen. Namhafte Hersteller wie zum Beispiel Audi und BMW bieten bereits hochautomatisierte Fahrzeuge in ihrem Portfolio an, die den Fahrer in alltäglichen Situationen entlasten. Das Fahrzeug kann unter Kontrolle des Fahrers selbstständig einparken oder in Stau-Situationen die Spur, sowie einen geschwindigkeitsabhängigen Sicherheitsabstand zu den vorausfahrenden Fahrzeugen einhalten. Im Notfall können Notbremsungen vom Fahrzeug selbst eingeleitet oder dem Fahrer mögliche Ausweichmanöver mitgeteilt und initiiert werden.\n",
    "\n",
    "Im Bereich der Luftfahrt werden, ähnlich zum Straßenverkehr, Flugvorgänge automatisiert, um die Piloten von monotonen Aufgaben zu entlasten und die Fehleranfälligkeit zu minimieren. Automatisiert bedeutet dabei, dass bestimmte Funktionen vom Piloten aktiv an das System übergeben werden. Das System arbeitet anschließend anhand von festen Programmen die Aufgaben ab. Anwendungsgebiete sind z.B. das Abfliegen eines Flugplanes im 3-dimensionalen Raum oder ein automatisierter Landeanflug.\n",
    "\n",
    "Die Abteilung für Flugsysteme beschäftigt sich am \\gls{DLR} in Braunschweig mit der Autonomisierung der \\gls{UA}. Umweltwahrnehmung, Flugregelung und Flugplanung zählen zu den hauptsächlichen Forschungsbereichen. Das Ziel ist der sichere und autonome Flugbetrieb.\n",
    "\n",
    "Der Begriff der Autonomie wird in der Wissenschaft unterschiedlich aufgefasst. Für diese Arbeit wird ein System als autonom betrachtet, wenn es seine Aktionen selbstständig plant, ausführt und auf Veränderungen der Umwelt entsprechend reagiert. Wird ein 3-dimensionaler Pfad (im Folgenden als Trajektorie bezeichnet) durch einen Menschen vorgegeben und vom System abgeflogen, so wird dies als hochautomatisiert, aber nicht als autonom, bezeichnet. Plant das System seinen Flugpfad auf Grund seiner Messwerte und Missionsvorgaben ohne Vorgabe eines Menschen, so wird dies als autonom bezeichnet.\n",
    "\n",
    "Um einem System die Autonomie zu ermöglichen, müssen einige grundlegende Fähigkeiten gegeben sein. Die erste Bedingung an das System ist das selbstständige Planen von Trajektorien. Bekannte Pfadplanungsansätze arbeiten mit Hinderniskarten, in denen die Hindernisse mit verschiedenen Eigenschaften (wie z.B. der Farbe, der Oberflächenstruktur, etc.) vermerkt werden. Durch bildgebende Sensoren, wie Laserscanner und Kameras, können detektierte Hindernisse zu diesen Karten hinzugefügt oder die vermerkten Eigenschaften der Hindernisse verbessert werden.\n",
    "\n",
    "Damit die von den Sensoren detektierten Hindernisse in die Karten eingetragen werden können, müssen die Sensordaten in ein gemeinsames Koordinatensystem überführt werden. Dafür werden die Sensordaten schrittweise zwischen verschiedenen Koordinatensystemen (Sensor-, Träger- und Weltkoordinatensystemen) transformiert.\n",
    "\n",
    "Die Transformation der Sensordaten in das globale Koordinatensystem oder in andere Sensorkoordinatensysteme enthält oft unbekannte und variable Parameter. Einerseits ist die genaue Position und Lage (Pose) des Sensors im Gehäuse unbekannt. Andererseits ist die Pose des Sensors auf dem Träger je nach Experiment unterschiedlich und auf Grund platzsparender Konstruktion nur sehr schwer messbar. Dadurch werden die Sensordaten falsch transformiert und die Sensor-Fusion erschwert.\n",
    "\n",
    "Die in dieser Arbeit präsentierte Lösung ermöglicht die automatische Bestimmung der Montagepose von \\gls{LiDAR}-Sensoren relativ zur \\gls{IMU}.\n",
    "\n",
    "Ausgangspunkt für den zu entwerfenden Ansatz sind relative Translationen und Rotationen (\\gls{6DoF}) des \\gls{LiDAR} zur betrachteten Umwelt. Diese werden mit Hilfe des \\gls{ICP} Algorithmus aus sukzessiven Aufnahmen bestimmt. Über den Abgleich der berechneten Transformation, der gemessenen Bewegung der \\gls{IMU} und dem Einsatz einer nicht linearen Optimierung, wird anschließend die \\gls{6DoF} Transformation zwischen den beiden Sensoren bestimmt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grundlagen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Die verwendeten Koordinatensysteme\n",
    "\n",
    "Autonome Systeme benötigen verschiedene Sensoren, um ihre Umwelt zu vermessen, zu klassifizieren und Entscheidungen zu treffen. Bevor die verschiedenen Daten in einen Zusammenhang gebracht werden können, müssen sie auf eine gemeinsame Datenbasis fusioniert werden.\n",
    "\n",
    "Jedes aufgenommene Datum eines Sensors befindet sich in einem Sensorkoordinatensystem. Der Ursprung des Koordinatensystems ist der Nullpunkt des Sensors, den jeder Sensorhersteller unterschiedlich definiert.  \n",
    "\n",
    "Die verschiedenen Sensoren sind auf einem Sensorträger befestigt. Der Ursprung des sogenannten Trägerkoordinatensystems ist meist der Ursprung der \\gls{IMU}. Alle Sensorposen werden relativ zur \\gls{IMU}-Pose ausgerichtet.\n",
    "\n",
    "Des Weiteren befindet sich das autonome System zu einem bestimmten Zeitpunkt in einer Lage und einer Position in seiner Umgebung. Dessen Bezugsort ist der Ursprung für das Weltkoordinatensystem.\n",
    "\n",
    "### Das Sensorkoordinatensystem\n",
    "\n",
    "Das Sensorkoordinatensystem ist je nach Sensor und Hersteller unterschiedlich definiert. Im Folgenden werden die Koordinatensysteme erläutert, die in dieser Arbeit hauptsächlich Anwendung finden.\n",
    "\n",
    "### Das Trägerkoordinatensystem\n",
    "\n",
    "Das Trägerkoordinatensystem beschreibt die Position und Lage der verschiedenen Sensoren zum Bezugspunkt des Trägers. Als Träger wird meist die Konstruktion bezeichnet, auf dem die Sensoren befestigt sind. Da in vielen Anwendungen auch Parameter gewünscht sind, die den Zustand des autonomen Systems beschreiben, wird in dieser Arbeit das autonome System als Träger betrachtet.\n",
    "\n",
    "Der Ursprung und die Ausrichtung der Koordinatenachsen hängt von der Anwendung des Trägers ab. Ein autonomes System hat die Aufgaben, autonom in einer unbekannten Welt zu navigieren und sich entsprechend zu bewegen. Aus diesem Grund wird der Ursprung des Koordinatensystems entweder in den Schwerpunkt des Trägers oder in das Sensorkoordinatensystem der Beschleunigungssensoren gelegt. Die Ausrichtung entspricht dabei der Hauptbewegungsrichtung des Trägers.\n",
    "\n",
    "### Das Weltkoordinatensystem\n",
    "\n",
    "Das [Weltkoordinatensystem](#fig:weltkugel) bezieht sich auf die Umgebung, in der sich der Träger bewegt. Das Koordinatensystem ist durch eine Höhe $Z$ im Bezug auf Normalnull der Erdoberfläche, und die Position durch Latitde und Longitude bestimmt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"fig:weltkugel\"></a>\n",
    "**Abbildung: Schematische Darstellung der Weltkugel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "WindowsError",
     "evalue": "[Error 2] Das System kann die angegebene Datei nicht finden",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWindowsError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-4523fa744324>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'asy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu'settings.render = 16;\\nimport three;\\nimport graph3;\\nimport solids;\\ncurrentprojection=orthographic(3, 3, 2);\\n\\nsize(16cm);\\n\\ndraw(surface(sphere(O,.7)),surfacepen=green+white+opacity(0.2), meshpen=0.2*white);\\ndraw(arc(c=O,-.7Z, .7Z, normal=X), black, L=Label(\"$Greenwich$\", position=Relative(0.8), align=E));\\ndraw(arc(c=O,.7Y, .7Y, normal=Z), black, L=Label(\"$Equator$\"));\\n\\ndraw(rotate(45, Y) * (.7Z--1.2Z), red, Arrow3(emissive(red)), L=Label(\"$Z_{world}$\", position=EndPoint));\\ndraw(arc(c=O,.7X, .7(X+Z)), red, arrow=Arrow3(emissive(red)), L=Label(\"$Longitude$\"));\\ndraw(arc(c=O,.7Y, .7X), red, arrow=Arrow3(emissive(red)), L=Label(\"$Latitude$\"));'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\ried_mi\\Desktop\\PortableApps\\Python2-7-6-1\\App\\lib\\site-packages\\ipython-3.1.0-py2.7.egg\\IPython\\core\\interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2262\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2263\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2264\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2265\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ried_mi\\.ipython\\extensions\\asymptote.py\u001b[0m in \u001b[0;36masy\u001b[1;34m(self, line, cell)\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ried_mi\\Desktop\\PortableApps\\Python2-7-6-1\\App\\lib\\site-packages\\ipython-3.1.0-py2.7.egg\\IPython\\core\\magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ried_mi\\.ipython\\extensions\\asymptote.py\u001b[0m in \u001b[0;36masy\u001b[1;34m(self, line, cell)\u001b[0m\n\u001b[0;32m    135\u001b[0m                 \u001b[1;31m# This avoids over-cluttering files.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mTemporaryAsymptoteFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtmp_asy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_asy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_asy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masy_files\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masy_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ried_mi\\.ipython\\extensions\\asymptote.py\u001b[0m in \u001b[0;36mrun_asy\u001b[1;34m(self, asy_file, img_file, fmt)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun_asy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0masy_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[1;34m\"\"\"Runs asy code in asy_file and returns IPython image\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[0masy_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0masy_stdout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_asy_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masy_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m         \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masy_stdout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0masy_img\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ried_mi\\.ipython\\extensions\\asymptote.py\u001b[0m in \u001b[0;36mrun_asy_file\u001b[1;34m(asy_file, img_file, fmt)\u001b[0m\n\u001b[0;32m    159\u001b[0m                                  \"-o\", img_file, asy_file],\n\u001b[0;32m    160\u001b[0m                                 \u001b[0mstdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m                                 stderr=subprocess.PIPE)\n\u001b[0m\u001b[0;32m    162\u001b[0m     \u001b[0masy_ret_code\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masy_proc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0masy_ret_code\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ried_mi\\Desktop\\PortableApps\\Python2-7-6-1\\App\\lib\\subprocess.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags)\u001b[0m\n\u001b[0;32m    707\u001b[0m                                 \u001b[0mp2cread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp2cwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m                                 errread, errwrite)\n\u001b[0m\u001b[0;32m    710\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m             \u001b[1;31m# Preserve original exception in case os.close raises.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ried_mi\\Desktop\\PortableApps\\Python2-7-6-1\\App\\lib\\subprocess.pyc\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, cwd, env, universal_newlines, startupinfo, creationflags, shell, to_close, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite)\u001b[0m\n\u001b[0;32m    955\u001b[0m                                          \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m                                          \u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 957\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m    958\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mpywintypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m                 \u001b[1;31m# Translate pywintypes.error to WindowsError, which is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWindowsError\u001b[0m: [Error 2] Das System kann die angegebene Datei nicht finden"
     ]
    }
   ],
   "source": [
    "%%asy\n",
    "settings.render = 16;\n",
    "import three;\n",
    "import graph3;\n",
    "import solids;\n",
    "currentprojection=orthographic(3, 3, 2);\n",
    "\n",
    "size(16cm);\n",
    "\n",
    "draw(surface(sphere(O,.7)),surfacepen=green+white+opacity(0.2), meshpen=0.2*white);\n",
    "draw(arc(c=O,-.7Z, .7Z, normal=X), black, L=Label(\"$Greenwich$\", position=Relative(0.8), align=E));\n",
    "draw(arc(c=O,.7Y, .7Y, normal=Z), black, L=Label(\"$Equator$\"));\n",
    "\n",
    "draw(rotate(45, Y) * (.7Z--1.2Z), red, Arrow3(emissive(red)), L=Label(\"$Z_{world}$\", position=EndPoint));\n",
    "draw(arc(c=O,.7X, .7(X+Z)), red, arrow=Arrow3(emissive(red)), L=Label(\"$Longitude$\"));\n",
    "draw(arc(c=O,.7Y, .7X), red, arrow=Arrow3(emissive(red)), L=Label(\"$Latitude$\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Koordinatentransformation nach Denavit-Hartenberg\n",
    "\n",
    "- Bezug auf Eigen\n",
    "\n",
    "Zur Verortung von Sensordaten in der globalen Weltkarte, müssen sie Schritt-für-Schritt vom Sensorkoordinatensystem in das Weltkoordinatensystem transformiert (überführt) werden. Diese Problematik ist vergleichbar mit der Bewegungsbeschreibung eines Roboterarmes. Dabei wird in jedes Gelenk ein Koordinatensystem gelegt, dessen Z-Achse in Richtung des nächsten Gelenks im Roboterarm zeigt. Folglich kann die Bewegung des Aktors durch die schrittweise Transformation zwischen den Gelenken oder durch eine einzige Transformationsmatrix beschrieben werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensortechnik\n",
    "\n",
    "Reflektivität, Laufzeitmessung, Fehlerbetrachtung\n",
    "\n",
    "### Lasersanner\n",
    "\n",
    "Laserscanner liefern die Messwerte im Allgemeinen in Polarkoordinaten. Dabei handelt es sich um Messwerte und Winkelangaben und sind abhängig vom Aufbau des \\gls{LiDAR}.\n",
    "\n",
    "- Verzerrung durch Bewegung\n",
    "- Distanzfehler (+/- 10 cm)\n",
    "- Winkelfehler\n",
    "\n",
    "### Inertiale Messeinheiten\n",
    "\n",
    "Aufbau:\n",
    "\n",
    "- Gyro\n",
    "- Beschleunigung\n",
    "\n",
    "- Masseschwerpunkt wird als Hauptbezugssystem verwendet\n",
    "\n",
    "#### Gyros\n",
    "\n",
    "Fehlerquellen:\n",
    "\n",
    "- Drift\n",
    "\n",
    "#### Beschleunigungssensoren\n",
    "\n",
    "Bewegungssensoren messen die Beschleunigungen in einer bestimmten Richtung und liefern meist skalare Messwerte. Werden mehrere Beschleunigungssensoren zusammengefasst, entsteht ein Sensorsystem, eine sogenannte \\gls{IMU}. Dieses Sensorsystem liefert je nach Ausführung mehrdimensionale Messwerte zur Bestimmung von Position und Lage in der  befindlichen Welt beschreiben.\n",
    "\n",
    "Fehlerquellen:\n",
    "\n",
    "- Ungenauigkeit des Beschleunigungssensors\n",
    "\n",
    "### Systeme zur globalen Positionsbestimmung\n",
    "\n",
    "- Notwendigkeit bei der Kalibrierung, die IMU zu stabilisieren?\n",
    "\n",
    "Fehlerquellen:\n",
    "\n",
    "- fehlerhaftes GPS (bis zu 15 m)\n",
    "\n",
    "### Systemfehler\n",
    "\n",
    "- Zeitlicher Versatz der Messungen zwischen Sensoren (lösbar durch Synchronisation)\n",
    "- Blindzeit (Sensoren messen in unterschiedlichen Intervallen)\n",
    "- fehlerhafte Angaben zur Pose zueinander"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithmen zur Transformation\n",
    "\n",
    "### ICP der PCL\n",
    "\n",
    "Fehlerquellen:\n",
    "\n",
    "- Rechenungenauigkeiten durch Transformationen\n",
    "- Elimination wichtiger Features bei Datenreduktion (z.B. Statistical Outlier Removal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Kalibrierung von LiDAR-Sensoren zu Inertialen Messeinheiten\n",
    "\n",
    "Sensoren stellen eine Grundlage der Wissensgewinnung für ein \\gls{UA} dar. Dieses Wissen kann anschließend in verschiedenen Algorithmen verwendet werden, um Trajektorien zu planen, zu verfolgen oder weiterführende Entscheidungen zu treffen. Die Voraussetzung für dieses Wissen ist die Glaubwürdigkeit. Glaubwürdigkeit bedeutet dabei, dass zur genauen Verortung von Hindernissen deren genaue Position bekannt sein muss. Die Sensoren sind an jeweils unterschiedlichen Posen am Träger, dem \\gls{UA}, angebracht. Einige Gründe dafür sind:\n",
    "\n",
    "- variable Grundkonfigurationen, die je nach Flugauftrag unterschiedliche Sensoren transportieren,\n",
    "- unterschiedliche Trägersysteme, da je nach Umgebung bestimmte \\gls{UA} eingesetzt werden müssen (Größen- oder Gewichtsbestimmungen)\n",
    "- verschiedene Beladungszustände, die eine Austarierung der Sensoren erfordern.\n",
    "\n",
    "Daraus resultiert, dass für jede unterschiedliche Verwendung des \\gls{UA} die Sensorparameter erneut kalibriert werden müssen. Bei bildgebenden Sensoren wie Kameras oder Laserscanner ist die genaue Bestimmung der Pose elementar, da es sonst nicht möglich ist, sichere und eindeutige Rückschlüsse auf die Umgebung ziehen zu können. Auf Grund einer nicht-planaren Trägeroberfläche und einer dynamischen Flotte an \\gls{UA}'s gibt es bisher kein automatisiertes Verfahren zur Kalibrierung. Bisher werden die Konfigurationen stets von Hand vermessen und kalibriert. Dadurch kommt es zu großen Ungenauigkeiten und Inkonsistenzen in den Vermessenen Positionen. Des Weiteren ist die Vermessung der Lage des Sensors sehr schwierig.\n",
    "\n",
    "Eine automatisierte Kalibrierung zwischen \\gls{LiDAR} und \\gls{IMU} Sensoren ermöglicht eine präzisere und deterministische Verwendung. Des Weiteren sollen die Träger problemlos angepasst oder ausgetauscht werden können. Die Kalibrierung soll eine genauere Bestimmung der Pose ermöglichen, als bisher von Hand möglich. Die folgenden Kapitel erläutern die verschiedenen in Betracht gezogenen Ansätze, beleuchten die jeweiligen Vor- und Nachteile und beschreiben die schlussendlich gewählte Implementierung.\n",
    "\n",
    "## Problemanalyse\n",
    "\n",
    "Die Bestimmung von Lage und Position im 3-dimensionalen Raum bezeichnet die Bestimmung von 6 Freiheitsgraden (\\gls{6DoF}). Die 6 Freiheitsgrade werden in 3 translatorische und 3 rotatorische Freiheitsgrade unterteilt. Die translatorischen Freiheitsgrade bestimmen die Position in $X$-, $Y$-, und $Z$-Achse in einem Weltkoordinatensystem. Die rotatorischen Freiheitsgrade bestimmen die Lage an dieser Position in Bezug zur Erdoberfläche. Gemäß \\ref{tbl:bezeichnung_der_winkel_gemaess_der_luftfahrt_din_9300} werden die 3 Eulerschen Winkeln $\\Phi$ (Phi), $\\Theta$ (Theta) und $\\Psi$ (Psi) verwendet.\n",
    "\n",
    "| Winkel   | Bezeichnung | Rotationsachse |\n",
    "| :-----   | :-------    | :-----:        |\n",
    "| $\\Phi$   | Gierwinkel  | $Z$            |\n",
    "| $\\Theta$ | Nickwinkel  | $Y$            |\n",
    "| $\\Psi$   | Rollwinkel  | $X$            |\n",
    "\n",
    "Table: Bezeichnung der Winkel gemäß DIN 9300 / ISO 1151-2:1985 \\label{tbl:bezeichnung_der_winkel_gemaess_der_luftfahrt_din_9300}\n",
    "\n",
    "\n",
    "## Möglichkeiten zur Kalibrierung\n",
    "\n",
    "Für die Kalibrierung der Sensoren werden folgende Anforderungen definiert:\n",
    "\n",
    "- die Umgebung wird als unveränderlich und starr angenommen,\n",
    "- die zu vermessende Bewegung muss größer als die größte Messungenauigkeit des Systems sein.\n",
    "\n",
    "### Im Sensorkoordinatensystem\n",
    "\n",
    "#### Ohne Bewegungskorrektur\n",
    "\n",
    "zeigt die Kalibrierung im Sensorkoordinaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%dot\n",
    "digraph G {\n",
    "    Ausgangspose [shape=rectangle, label=\"Ausgangspose (AP)\", group=g1];\n",
    "    Bewegung [shape=none, label=\"Veränderung durch\\nBewegung\" , group=g2];\n",
    "    Endpose [shape=rectangle, label=\"Endpose (EP)\", group=g3];\n",
    "    MontagePose [shape=rectangle, label=\"Sensorpose zur IMU\", group=g2];\n",
    "    ICP [shape=doubleoctagon, label=\"ICP\", group=g2];\n",
    "    IMU [label=\"IMU\", group=g2];\n",
    "    Abgleich [shape=doubleoctagon, label=\"Abgleich\", group=g2];\n",
    "\n",
    "    Scan_AP [label=\"Sensorkoordinaten\", group=g1];\n",
    "    Scan_EP [label=\"Sensorkoordinaten\", group=g3];\n",
    "\n",
    "    {\n",
    "        rank=same;\n",
    "            Ausgangspose; Endpose; Bewegung;\n",
    "    }\n",
    "\n",
    "    Ausgangspose -> Bewegung [style=dotted, arrowhead=none];\n",
    "    Bewegung -> Endpose [style=dotted, arrowhead=none];\n",
    "    Bewegung -> IMU [style=dotted, arrowhead=none];\n",
    "    Ausgangspose -> Scan_AP [label=\" Umgebungsscan\\nausgeführt\"];\n",
    "    Endpose -> Scan_EP [label=\" Umgebungsscan\\nausgeführt\"];\n",
    "\n",
    "    Scan_AP -> ICP;\n",
    "    Scan_EP -> ICP;\n",
    "    ICP -> Abgleich;\n",
    "    IMU -> Abgleich;\n",
    "    \n",
    "    Abgleich -> MontagePose [label=\" entspricht\"];\n",
    "}\n",
    "# FIGURE: Kalibrierung im Sensorkoordinatensystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mit Bewegungskorrektur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%dot\n",
    "digraph SC {\n",
    "    Ausgangspose [shape=rectangle, label=\"Ausgangspose (AP)\", group=g1];\n",
    "    Bewegung [shape=none, label=\"Veränderung durch\\nBewegung\" , group=g2];\n",
    "    Endpose [shape=rectangle, label=\"Endpose (EP)\", group=g3];\n",
    "    MontagePose [shape=rectangle, label=\"Sensorpose zur IMU\", group=g2];\n",
    "    ICP [shape=doubleoctagon, label=\"ICP\", group=g2];\n",
    "    IMU [label=\"IMU\", group=g2];\n",
    "    Abgleich [shape=doubleoctagon, label=\"Abgleich\", group=g2];\n",
    "\n",
    "    Scan_AP [label=\"Umgebungsscan\", group=g1];\n",
    "    Scan_zu_SK1 [shape=diamond, label=\"1a\", group=g1];\n",
    "    Scan_AP_SK [label=\"Sensorkoordinaten\", group=g1];\n",
    "    Scan_EP [label=\"Umgebungsscan\", group=g3];\n",
    "    Scan_zu_SK2 [shape=diamond, label=\"1b\", group=g3];\n",
    "    Scan_EP_SK [label=\"Sensorkoordinaten\", group=g3];\n",
    "\n",
    "    {\n",
    "        rank=same;\n",
    "            Ausgangspose; Endpose; Bewegung;\n",
    "    }\n",
    "\n",
    "    {\n",
    "        rank=same;\n",
    "            Scan_zu_SK1; Scan_zu_SK2;\n",
    "    }\n",
    "\n",
    "    Ausgangspose -> Bewegung [style=dotted, arrowhead=none];\n",
    "    Bewegung -> Endpose [style=dotted, arrowhead=none];\n",
    "    Bewegung -> IMU [style=dotted, arrowhead=none];\n",
    "    Ausgangspose -> Scan_AP;\n",
    "    Endpose -> Scan_EP;\n",
    "\n",
    "    Scan_AP -> Scan_zu_SK1 -> Scan_AP_SK -> ICP;\n",
    "    Scan_EP -> Scan_zu_SK2 -> Scan_EP_SK -> ICP;\n",
    "    ICP -> Abgleich;\n",
    "\n",
    "    IMU -> Scan_zu_SK1;\n",
    "    IMU -> Scan_zu_SK2;\n",
    "    IMU -> Abgleich;\n",
    "    \n",
    "    Abgleich -> MontagePose [label=\" entspricht\"];\n",
    "}\n",
    "# FIGURE: Kalibrierung im Sensorkoordinatensystem mit Bewegungskorrektur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Im Weltkoordinatensystem\n",
    "\n",
    "#### Ohne Bewegungskorrektur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%dot\n",
    "digraph WC {\n",
    "    {   node [group=g1]\n",
    "        Scan_AP_SK [label=\"Sensorkoordinaten\"];\n",
    "        Scan_AP_TK [label=\"Trägerkoordinaten\"];\n",
    "        Scan_AP_WK [label=\"Weltkoordinaten (rel.)\"];\n",
    "        node [shape=rectangle]\n",
    "        Ausgangspose [label=\"Ausgangspose (AP)\"];\n",
    "        node [shape=diamond]\n",
    "        SK_zu_TK1 [label=\"1a\"];\n",
    "        TK_zu_WK1 [label=\"2a\"];\n",
    "    }\n",
    "\n",
    "    {   node [group=g2]\n",
    "        Bewegung [shape=none, label=\"Veränderung durch\\nBewegung\"];\n",
    "        IMU [label=\"IMU\"];\n",
    "        ICP [shape=doubleoctagon, label=\"ICP\"];\n",
    "        MontagePose [shape=rectangle, label=\"Sensorpose zur IMU\"];\n",
    "    }\n",
    "\n",
    "    {   node [group=g3]\n",
    "        Scan_EP_SK [label=\"Sensorkoordinaten\"];\n",
    "        Scan_EP_TK [label=\"Trägerkoordinaten\"];\n",
    "        Scan_EP_WK [label=\"Weltkoordinaten (rel.)\"];\n",
    "        node [shape=rectangle]\n",
    "        Endpose [label=\"Endpose (EP)\"];\n",
    "        node [shape=diamond]\n",
    "        SK_zu_TK2 [label=\"1b\"];\n",
    "        TK_zu_WK2 [label=\"2b\"];\n",
    "    }\n",
    "\n",
    "    {   rank=same;\n",
    "            Ausgangspose; Endpose; Bewegung;\n",
    "    }\n",
    "\n",
    "    {   rank=same;\n",
    "            SK_zu_TK1; SK_zu_TK2;\n",
    "    }\n",
    "\n",
    "    {   edge [style=dotted, arrowhead=none]\n",
    "        Ausgangspose -> Bewegung;\n",
    "        Bewegung -> Endpose;\n",
    "        Bewegung -> IMU;\n",
    "    }\n",
    "    Ausgangspose -> Scan_AP_SK [label=\" Umgebungsscan\\nausgeführt\"];\n",
    "    Endpose -> Scan_EP_SK [label=\" Umgebungsscan\\nausgeführt\"];\n",
    "\n",
    "    IMU -> TK_zu_WK1;\n",
    "\n",
    "    MontagePose -> SK_zu_TK1;\n",
    "    MontagePose -> SK_zu_TK2;\n",
    "\n",
    "    Scan_AP_SK -> SK_zu_TK1 -> Scan_AP_TK -> TK_zu_WK1 -> Scan_AP_WK -> ICP;\n",
    "    Scan_EP_SK -> SK_zu_TK2 -> Scan_EP_TK -> TK_zu_WK2 -> Scan_EP_WK -> ICP;\n",
    "\n",
    "    ICP -> MontagePose [style=dotted, label=\" update\"];\n",
    "}\n",
    "# FIGURE: Kalibrierung im Weltkoordinatensystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mit Bewegungskorrektur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%dot\n",
    "digraph WC {\n",
    "    {   node [group=g1]\n",
    "        Scan_AP [label=\"Umgebungsscan\"];\n",
    "        Scan_AP_SK [label=\"Sensorkoordinaten\"];\n",
    "        Scan_AP_TK [label=\"Trägerkoordinaten\"];\n",
    "        Scan_AP_WK [label=\"Weltkoordinaten (rel.)\"];\n",
    "        node [shape=rectangle]\n",
    "        Ausgangspose [label=\"Ausgangspose (AP)\", group=g1];\n",
    "        node [shape=diamond]\n",
    "        Scan_zu_SK1 [label=\"1a\"];\n",
    "        SK_zu_TK1 [label=\"2a\"];\n",
    "        TK_zu_WK1 [label=\"3a\"];\n",
    "    }\n",
    "\n",
    "    {   node [group=g2]\n",
    "        Bewegung [shape=none, label=\"Veränderung durch\\nBewegung\"];\n",
    "        IMU [label=\"IMU\"];\n",
    "        ICP [shape=doubleoctagon, label=\"ICP\"];\n",
    "        MontagePose [shape=rectangle, label=\"Sensorpose zur IMU\", group=g2];\n",
    "    }\n",
    "\n",
    "    {   node [group=g3]\n",
    "        Scan_EP [label=\"Umgebungsscan\"];\n",
    "        Scan_EP_SK [label=\"Sensorkoordinaten\"];\n",
    "        Scan_EP_TK [label=\"Trägerkoordinaten\"];\n",
    "        Scan_EP_WK [label=\"Weltkoordinaten (rel.)\"];\n",
    "        node [shape=rectangle]\n",
    "        Endpose [label=\"Endpose (EP)\", group=g3];\n",
    "        node [shape=diamond]\n",
    "        Scan_zu_SK2 [label=\"1b\"];\n",
    "        SK_zu_TK2 [label=\"2b\"];\n",
    "        TK_zu_WK2 [label=\"3b\"];\n",
    "    }\n",
    "\n",
    "    {   rank=same;\n",
    "            Ausgangspose; Endpose; Bewegung;\n",
    "    }\n",
    "\n",
    "    {   rank=same;\n",
    "            Scan_zu_SK1; Scan_zu_SK2;\n",
    "    }\n",
    "\n",
    "    {   rank=same;\n",
    "            SK_zu_TK1; SK_zu_TK2;\n",
    "    }\n",
    "\n",
    "    {   edge [style=dotted, arrowhead=none]\n",
    "        Ausgangspose -> Bewegung;\n",
    "        Bewegung -> Endpose;\n",
    "        Bewegung -> IMU;\n",
    "    }\n",
    "    Ausgangspose -> Scan_AP;\n",
    "    Endpose -> Scan_EP;\n",
    "\n",
    "    IMU -> Scan_zu_SK1;\n",
    "    IMU -> Scan_zu_SK2;\n",
    "    IMU -> TK_zu_WK1;\n",
    "\n",
    "    MontagePose -> SK_zu_TK1;\n",
    "    MontagePose -> SK_zu_TK2;\n",
    "\n",
    "    Scan_AP -> Scan_zu_SK1 -> Scan_AP_SK -> SK_zu_TK1 -> Scan_AP_TK -> TK_zu_WK1 -> Scan_AP_WK -> ICP;\n",
    "    Scan_EP -> Scan_zu_SK2 -> Scan_EP_SK -> SK_zu_TK2 -> Scan_EP_TK -> TK_zu_WK2 -> Scan_EP_WK -> ICP;\n",
    "\n",
    "    ICP -> MontagePose [style=dotted, label=\" update\"];\n",
    "}\n",
    "# FIGURE: Kalibrierung im Weltkoordinatensystem mit Bewegungskorrektur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validierung\n",
    "\n",
    "**Einsatzgebiet: autonomer Hubschrauberflug**\n",
    "\n",
    "Zur Validierung der Kalibier-Lösung wurden zwei Experimente durchgeführt. Das erste Experiment dient zur Bestimmung des \"Common Ground\" anhand eines konstruierten und vermessenen Aufbaus. Das zweite Experiment dient der Erprobung an einem Flugversuch eines automatisierten Hubschraubers. Im Folgenden werden beide Experimente bezüglich ihres Aufbaus, des Ablaufs und den jeweiligen Resultaten erläutert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versuch - \"Common Ground\"\n",
    "\n",
    "### Aufbau\n",
    "\n",
    "**Welche Sensorprodukte werden wie verwendet (Eigenschaften, Auflösungen etc.)?**\n",
    "\n",
    "Mit dem Experiment wird die Genauigkeit der Kalibrierungslösung bestimmt. Der Aufbau ist minimal und besteht rein aus den zur Kalibrierung benötigten Geräten.\n",
    "\n",
    "#### Der Laserscanner\n",
    "\n",
    "Als Laserscanner kommt der Velodyne HDL-32e (im Folgenden als Velodyne bezeichnet) zum Einsatz. Der Sichtbereich des Velodyne beträgt 360° um seine Y-Achse. Durch 32 vertikal angeordnete Laserquellen beträgt der Sichtbereich in der ZX-Ebene zwischen +10° und -30°. Der Messbereich liegt bei 1m bis 100m mit einer Standardabweichung von +/- 2cm bei 25m. Die horizontale Auflösung ist abhängig von der, vom Anwender eingestellten, Bildrate (Framerate). Die Framerate kann vom Benutzer zwischen 5Hz und 20Hz gewählt werden. Für diesen Versuch wurde die Framerate auf 10Hz eingestellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "WindowsError",
     "evalue": "[Error 2] Das System kann die angegebene Datei nicht finden",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWindowsError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-b2b0f8c1e301>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'asy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu'//settings.render=16;\\n\\ncurrentprojection=orthographic(3,4,1, center=true);\\n\\nsize(15cm);\\npen outside = white+opacity(1);\\n\\nreal height=0.8;\\npath3 laserBase = path3((-0.4,0.7) -- (-0.5,sin(acos(-0.5))) .. (-1,0) .. (0,-1) .. (1,0) .. (0.5,sin(acos(0.5))) -- (0.4,0.7));\\nsurface laserEye = extrude(laserBase --- cycle, height*Z);\\n\\ndraw(shift(0.9Z) * scale(1,1,0.4) * unithemisphere, surfacepen=outside); // Top\\ndraw(shift(0.4Z) * scale(1,1,0.5) * unitcylinder, surfacepen=outside);   // upper rotating Head\\ndraw(shift(-height/2*Z) * laserEye, surfacepen=white+opacity(0.8));      // Laser-Eye\\ndraw(shift(-0.7Z) * scale(1,1,0.3) * unitcylinder, surfacepen=outside);  // lower rotating Head\\ndraw(shift(-1.7Z) * scale(1,1,0.95) * unitcylinder, surfacepen=outside); // Base\\n\\ndraw(rotate(-90,X) * (O--3Y), red, Arrow3(emissive(red)), L=Label(\"$Y$\", position=EndPoint));\\ndraw(rotate(-90,X) * (O--3Z), red, Arrow3(emissive(red)), L=Label(\"$Z$\", position=EndPoint));\\ndraw(rotate(-90,X) * arc(c=(0,0,0),1.1Z, 1.1X), red, arrow=Arrow3(emissive(red)), L=Label(\"$\\\\Theta$\"));'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\ried_mi\\Desktop\\PortableApps\\Python2-7-6-1\\App\\lib\\site-packages\\ipython-3.1.0-py2.7.egg\\IPython\\core\\interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2262\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2263\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2264\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2265\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ried_mi\\.ipython\\extensions\\asymptote.py\u001b[0m in \u001b[0;36masy\u001b[1;34m(self, line, cell)\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ried_mi\\Desktop\\PortableApps\\Python2-7-6-1\\App\\lib\\site-packages\\ipython-3.1.0-py2.7.egg\\IPython\\core\\magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ried_mi\\.ipython\\extensions\\asymptote.py\u001b[0m in \u001b[0;36masy\u001b[1;34m(self, line, cell)\u001b[0m\n\u001b[0;32m    135\u001b[0m                 \u001b[1;31m# This avoids over-cluttering files.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mTemporaryAsymptoteFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtmp_asy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_asy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_asy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masy_files\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masy_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ried_mi\\.ipython\\extensions\\asymptote.py\u001b[0m in \u001b[0;36mrun_asy\u001b[1;34m(self, asy_file, img_file, fmt)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun_asy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0masy_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[1;34m\"\"\"Runs asy code in asy_file and returns IPython image\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[0masy_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0masy_stdout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_asy_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masy_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m         \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masy_stdout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0masy_img\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ried_mi\\.ipython\\extensions\\asymptote.py\u001b[0m in \u001b[0;36mrun_asy_file\u001b[1;34m(asy_file, img_file, fmt)\u001b[0m\n\u001b[0;32m    159\u001b[0m                                  \"-o\", img_file, asy_file],\n\u001b[0;32m    160\u001b[0m                                 \u001b[0mstdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m                                 stderr=subprocess.PIPE)\n\u001b[0m\u001b[0;32m    162\u001b[0m     \u001b[0masy_ret_code\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masy_proc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0masy_ret_code\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ried_mi\\Desktop\\PortableApps\\Python2-7-6-1\\App\\lib\\subprocess.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags)\u001b[0m\n\u001b[0;32m    707\u001b[0m                                 \u001b[0mp2cread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp2cwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m                                 errread, errwrite)\n\u001b[0m\u001b[0;32m    710\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m             \u001b[1;31m# Preserve original exception in case os.close raises.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ried_mi\\Desktop\\PortableApps\\Python2-7-6-1\\App\\lib\\subprocess.pyc\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, cwd, env, universal_newlines, startupinfo, creationflags, shell, to_close, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite)\u001b[0m\n\u001b[0;32m    955\u001b[0m                                          \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m                                          \u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 957\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m    958\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mpywintypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m                 \u001b[1;31m# Translate pywintypes.error to WindowsError, which is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWindowsError\u001b[0m: [Error 2] Das System kann die angegebene Datei nicht finden"
     ]
    }
   ],
   "source": [
    "%%asy\n",
    "//settings.render=16;\n",
    "import three;\n",
    "import graph3;\n",
    "import solids;\n",
    "currentprojection=orthographic(3,4,1, center=true);\n",
    "\n",
    "size(15cm);\n",
    "pen outside = white+opacity(1);\n",
    "\n",
    "real height=0.8;\n",
    "path3 laserBase = path3((-0.4,0.7) -- (-0.5,sin(acos(-0.5))) .. (-1,0) .. (0,-1) .. (1,0) .. (0.5,sin(acos(0.5))) -- (0.4,0.7));\n",
    "surface laserEye = extrude(laserBase --- cycle, height*Z);\n",
    "\n",
    "draw(shift(0.9Z) * scale(1,1,0.4) * unithemisphere, surfacepen=outside); // Top\n",
    "draw(shift(0.4Z) * scale(1,1,0.5) * unitcylinder, surfacepen=outside);   // upper rotating Head\n",
    "draw(shift(-height/2*Z) * laserEye, surfacepen=white+opacity(0.8));      // Laser-Eye\n",
    "draw(shift(-0.7Z) * scale(1,1,0.3) * unitcylinder, surfacepen=outside);  // lower rotating Head\n",
    "draw(shift(-1.7Z) * scale(1,1,0.95) * unitcylinder, surfacepen=outside); // Base\n",
    "\n",
    "draw(rotate(-90,X) * (O--3Y), red, Arrow3(emissive(red)), L=Label(\"$Y$\", position=EndPoint));\n",
    "draw(rotate(-90,X) * (O--3Z), red, Arrow3(emissive(red)), L=Label(\"$Z$\", position=EndPoint));\n",
    "draw(rotate(-90,X) * arc(c=(0,0,0),1.1Z, 1.1X), red, arrow=Arrow3(emissive(red)), L=Label(\"$\\Theta$\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Laserscanner misst den Rotationswinkel $\\Theta$, die Distanz zum Objekt, dem Intensitätswert des jeweiligen Hits (ein Hit bezeichnet den Auftreffpunkt des Laserstrahls auf einem Objekt) und einem Zeitstempel. Die aufgenommenen Sensordaten werden per \\gls{UDP} an den Flugrechner weitergeleitet und dort in Sensorkorrdinaten transformiert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Die inertiale Messeinheit\n",
    "\n",
    "Als inertiale Messeinheit kommt die iMar \\gls{IMU} iTraceRT-F400-Q zum Einsatz. Die \\gls{IMU} bietet eine \"Deep-Coupled\" Sensorumgebung aus \\gls{INS} und \\gls{GNSS} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Antenne 1</th>\n",
       "      <th>Antenne 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td> 44.5</td>\n",
       "      <td>-114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td> 11.0</td>\n",
       "      <td>   0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z</th>\n",
       "      <td> -2.0</td>\n",
       "      <td>  -3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Antenne 1  Antenne 2\n",
       "X       44.5       -114\n",
       "Y       11.0          0\n",
       "Z       -2.0         -3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd #FIGURE: Abstand der GPS-Antennen zur IMU in cm\n",
    "pd.DataFrame(data={'Antenne 1' : [44.5,11,-2], 'Antenne 2' : [-114,0,-3]}, index=['X','Y','Z'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ablauf\n",
    "\n",
    "Während eines Experimentalfluges werden in regelmäßigen Abständen Bewegungs- und Laserdaten aufgenommen. Die Abstände richten sich nach den jeweiligen Fähigkeiten der Sensoren.\n",
    "\n",
    "```Bash\n",
    "./dip/bin/obdip-release-linux64-g++\n",
    "./artis/bin/itracert-logger-release-linux64-g++\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultat\n",
    "\n",
    "## Gesamtresultat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fazit und Ausblick\n",
    "\n",
    "1. Was wurde gemacht?\n",
    "2. Was war das Resultat?\n",
    "3. Was ergeben sich für Folgeaufgaben?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
